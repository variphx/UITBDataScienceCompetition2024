{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.10' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch\n",
    "import easyocr\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.functional import f1_score\n",
    "from lightning.pytorch import callbacks as L_callbacks\n",
    "from transformers import AutoModel, AutoImageProcessor\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "DATA_DIR = \"/kaggle/input/vimmsd-uit2024\"\n",
    "CLASS_NAMES = [\"not-sarcasm\", \"image-sarcasm\", \"text-sarcasm\", \"multi-sarcasm\"]\n",
    "IMAGE_PROCESSOR = AutoImageProcessor.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\", use_fast=True\n",
    ")\n",
    "OCR = easyocr.Reader([\"vi\", \"en\"])\n",
    "\n",
    "\n",
    "class DscTrainDataset(Dataset):\n",
    "    def __init__(self, data_dir: str = DATA_DIR, class_names: list[str] = CLASS_NAMES):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_dir = Path(data_dir)\n",
    "        images_dir = self.data_dir.joinpath(\"training-images\", \"train-images\")\n",
    "        data_file = self.data_dir.joinpath(\"vimmsd-train.json\")\n",
    "\n",
    "        label2id = dict([(class_name, id) for id, class_name in enumerate(class_names)])\n",
    "        self.label2id = label2id\n",
    "\n",
    "        with open(data_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        mapped_data = []\n",
    "\n",
    "        for key in tqdm(\n",
    "            data, desc=\"Mapping image file name to file path\", total=len(data)\n",
    "        ):\n",
    "            data_i = data[key]\n",
    "\n",
    "            image_path = images_dir.joinpath(data_i[\"image\"]).as_posix()\n",
    "            caption = data_i[\"caption\"]\n",
    "            label = data_i[\"label\"]\n",
    "\n",
    "            mapped_data.append(\n",
    "                {\"image\": image_path, \"caption\": caption, \"label\": label2id[label]}\n",
    "            )\n",
    "\n",
    "        self.data = mapped_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        item[\"image\"] = Image.open(item[\"image\"]).convert(\"RGB\")\n",
    "        return item\n",
    "\n",
    "\n",
    "class DscPredictDataset(Dataset):\n",
    "    def __init__(self, data_dir: str = DATA_DIR):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_dir = Path(data_dir)\n",
    "        images_dir = self.data_dir.joinpath(\"public-test-images\", \"dev-images\")\n",
    "        data_file = self.data_dir.joinpath(\"vimmsd-public-test.json\")\n",
    "\n",
    "        with open(data_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        mapped_data = []\n",
    "\n",
    "        for key in tqdm(\n",
    "            data, desc=\"Mapping image file name to file path\", total=len(data)\n",
    "        ):\n",
    "            data_i = data[key]\n",
    "\n",
    "            image_path = images_dir.joinpath(data_i[\"image\"]).as_posix()\n",
    "            caption = data_i[\"caption\"]\n",
    "\n",
    "            mapped_data.append({\"image\": image_path, \"caption\": caption})\n",
    "\n",
    "        self.data = mapped_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        item[\"image\"] = Image.open(item[\"image\"]).convert(\"RGB\")\n",
    "        return item\n",
    "\n",
    "\n",
    "def collate_fn(batch: list[dict[str, any]], image_processor=IMAGE_PROCESSOR, ocr=OCR):\n",
    "    images = []\n",
    "    image_texts = []\n",
    "    captions = []\n",
    "    labels = []\n",
    "\n",
    "    for item in batch:\n",
    "        image = np.array(item[\"image\"])\n",
    "        images.append(image)\n",
    "\n",
    "        image_text = \"\\n\".join(\n",
    "            list(lambda bounding_box, text, confident: text, ocr.readtext(image))\n",
    "        )\n",
    "\n",
    "        image_texts.append(image_text)\n",
    "        captions.append(item[\"caption\"])\n",
    "        labels.append(item.get(\"label\"))\n",
    "\n",
    "    images = image_processor(images, return_tensors=\"pt\")\n",
    "\n",
    "    return (\n",
    "        {\"images\": images, \"image_texts\": image_texts, \"captions\": captions},\n",
    "        labels,\n",
    "    )\n",
    "\n",
    "\n",
    "class CombinedSarcasmClassifier(L.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        text_encoder = SentenceTransformer(\n",
    "            \"jinaai/jina-embeddings-v3\", trust_remote_code=True\n",
    "        )\n",
    "        text_encoder.train()\n",
    "        self.text_encoder = text_encoder\n",
    "\n",
    "        image_encoder = AutoModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        image_encoder.train()\n",
    "        self.image_encoder = image_encoder\n",
    "\n",
    "        self.fc = nn.LazyLinear(4)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.text_encoder.to(self.device, self.dtype)\n",
    "        self.image_encoder.to(self.device, self.dtype)\n",
    "\n",
    "    def forward(self, images, image_texts, captions):\n",
    "        # with torch.no_grad():\n",
    "        images = self.image_encoder(**images).last_hidden_state[:, 0]\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "        image_texts = self.text_encoder.encode(\n",
    "            image_texts, convert_to_tensor=True, show_progress_bar=False\n",
    "        )\n",
    "        image_texts = image_texts.view(image_texts.shape[0], -1)\n",
    "\n",
    "        captions = self.text_encoder.encode(\n",
    "            captions, convert_to_tensor=True, show_progress_bar=False\n",
    "        )\n",
    "        captions = captions.view(captions.shape[0], -1)\n",
    "\n",
    "        embeddings = torch.cat([images, image_texts, captions], dim=1)\n",
    "        logits = self.fc(embeddings)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        features, targets = batch\n",
    "        logits = self.forward(**features)\n",
    "        targets = torch.tensor(targets, device=self.device)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        f1 = f1_score(\n",
    "            F.softmax(logits, dim=1),\n",
    "            targets,\n",
    "            task=\"multiclass\",\n",
    "            num_classes=len(CLASS_NAMES),\n",
    "        )\n",
    "        self.log_dict(\n",
    "            {\"train_loss\": loss, \"train_f1\": f1},\n",
    "            prog_bar=True,\n",
    "            batch_size=logits.shape[0],\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        features, targets = batch\n",
    "        targets = torch.tensor(targets, device=self.device)\n",
    "        logits = self.forward(**features)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        f1 = f1_score(\n",
    "            F.softmax(logits, dim=1),\n",
    "            targets,\n",
    "            task=\"multiclass\",\n",
    "            num_classes=len(CLASS_NAMES),\n",
    "        )\n",
    "        self.log_dict(\n",
    "            {\"val_loss\": loss, \"val_f1\": f1},\n",
    "            prog_bar=True,\n",
    "            batch_size=logits.shape[0],\n",
    "        )\n",
    "\n",
    "    def predict_step(self, batch, _):\n",
    "        features, _ = batch\n",
    "        logits = self.forward(**features)\n",
    "        predictions = F.softmax(logits, dim=1).argmax(dim=1)\n",
    "        return predictions\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), 5e-5)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "train_ds = DscTrainDataset()\n",
    "train_ds, val_ds = torch.utils.data.random_split(train_ds, [0.85, 0.15])\n",
    "train_dataloader = DataLoader(\n",
    "    train_ds, collate_fn=collate_fn, batch_size=128, num_workers=3\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_ds, collate_fn=collate_fn, batch_size=128, num_workers=3\n",
    ")\n",
    "\n",
    "model = CombinedSarcasmClassifier().to(torch.bfloat16)\n",
    "\n",
    "callbacks = [L_callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0.001)]\n",
    "trainer = L.Trainer(max_epochs=-1, callbacks=callbacks)\n",
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n",
    "predict_ds = DscPredictDataset()\n",
    "predict_dataloader = DataLoader(\n",
    "    predict_ds, collate_fn=collate_fn, batch_size=128, num_workers=3\n",
    ")\n",
    "predictions = trainer.predict(dataloaders=predict_dataloader, ckpt_path=\"best\")\n",
    "\n",
    "results = {}\n",
    "for step, batch in (prog_bar := tqdm(enumerate(predictions), desc=\"Predicting\")):\n",
    "    for index, prediction in enumerate(batch):\n",
    "        index = str((step * batch.shape[0]) + index)\n",
    "        prediction = CLASS_NAMES[prediction]\n",
    "        results.update({index: prediction})\n",
    "        prog_bar.set_postfix({\"label\": prediction})\n",
    "        prog_bar.refresh()\n",
    "results = {\"results\": results, \"phase\": \"dev\"}\n",
    "\n",
    "with open(\"/kaggle/working/results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
